# -*- coding: utf-8 -*-
"""
AstrBot ç½‘é¡µåˆ†ææ’ä»¶
è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·å‘é€çš„ç½‘é¡µé“¾æ¥ï¼ŒæŠ“å–å†…å®¹å¹¶è°ƒç”¨LLMè¿›è¡Œåˆ†æå’Œæ€»ç»“
"""

import re
import asyncio
from typing import List, Optional
from urllib.parse import urlparse

import httpx
from bs4 import BeautifulSoup

from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from astrbot.api.message_components import Plain, Image


class WebAnalyzer:
    """ç½‘é¡µåˆ†æå™¨ç±»"""
    
    def __init__(self, max_content_length: int = 10000, timeout: int = 30, user_agent: str = None):
        self.max_content_length = max_content_length
        self.timeout = timeout
        self.user_agent = user_agent or 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        self.client = None
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.client = httpx.AsyncClient(timeout=self.timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.client:
            await self.client.aclose()
    
    def extract_urls(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–URLé“¾æ¥"""
        # åŒ¹é…å¸¸è§çš„URLæ ¼å¼
        url_pattern = r'https?://[^\s\u4e00-\u9fff]+'
        urls = re.findall(url_pattern, text)
        return urls
    
    def is_valid_url(self, url: str) -> bool:
        """éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except Exception:
            return False
    
    async def fetch_webpage(self, url: str) -> Optional[str]:
        """æŠ“å–ç½‘é¡µå†…å®¹"""
        try:
            headers = {
                'User-Agent': self.user_agent
            }
            
            response = await self.client.get(url, headers=headers, follow_redirects=True)
            response.raise_for_status()
            
            return response.text
        except Exception as e:
            logger.error(f"æŠ“å–ç½‘é¡µå¤±è´¥: {url}, é”™è¯¯: {e}")
            return None
    
    def extract_content(self, html: str, url: str) -> dict:
        """ä»HTMLä¸­æå–ä¸»è¦å†…å®¹"""
        try:
            soup = BeautifulSoup(html, 'lxml')
            
            # æå–æ ‡é¢˜
            title = soup.find('title')
            title_text = title.get_text().strip() if title else "æ— æ ‡é¢˜"
            
            # å°è¯•æå–æ–‡ç« å†…å®¹ï¼ˆä¼˜å…ˆé€‰æ‹©articleã€mainç­‰è¯­ä¹‰åŒ–æ ‡ç­¾ï¼‰
            content_selectors = [
                'article',
                'main',
                '.article-content',
                '.post-content',
                '.content',
                'body'
            ]
            
            content_text = ""
            for selector in content_selectors:
                element = soup.select_one(selector)
                if element:
                    # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
                    for script in element(['script', 'style']):
                        script.decompose()
                    
                    text = element.get_text(separator='\n', strip=True)
                    if len(text) > len(content_text):
                        content_text = text
            
            # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„å†…å®¹ï¼Œä½¿ç”¨body
            if not content_text:
                body = soup.find('body')
                if body:
                    for script in body(['script', 'style']):
                        script.decompose()
                    content_text = body.get_text(separator='\n', strip=True)
            
            # é™åˆ¶å†…å®¹é•¿åº¦
            if len(content_text) > self.max_content_length:
                content_text = content_text[:self.max_content_length] + "..."
            
            return {
                'title': title_text,
                'content': content_text,
                'url': url
            }
        except Exception as e:
            logger.error(f"è§£æç½‘é¡µå†…å®¹å¤±è´¥: {e}")
            return None


from astrbot.api import AstrBotConfig

@register("astrbot_plugin_web_analyzer", "Sakura520222", "è‡ªåŠ¨è¯†åˆ«ç½‘é¡µé“¾æ¥å¹¶è¿›è¡Œå†…å®¹åˆ†æå’Œæ€»ç»“", "1.0.0", "https://github.com/Sakura520222/astrbot_plugin_web_analyzer")
class WebAnalyzerPlugin(Star):
    """ç½‘é¡µåˆ†ææ’ä»¶ä¸»ç±»"""
    
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        
        # ä»é…ç½®è·å–å‚æ•°
        self.max_content_length = config.get('max_content_length', 10000)
        self.timeout = config.get('request_timeout', 30)
        self.llm_enabled = config.get('llm_enabled', True)
        self.auto_analyze = config.get('auto_analyze', True)
        self.user_agent = config.get('user_agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        self.allowed_domains = self._parse_domain_list(config.get('allowed_domains', ''))
        self.blocked_domains = self._parse_domain_list(config.get('blocked_domains', ''))
        
        # åˆ†æè®¾ç½®
        analysis_settings = config.get('analysis_settings', {})
        self.enable_emoji = analysis_settings.get('enable_emoji', True)
        self.enable_statistics = analysis_settings.get('enable_statistics', True)
        self.max_summary_length = analysis_settings.get('max_summary_length', 2000)
        
        # LLMæä¾›å•†é…ç½®
        self.llm_provider = config.get('llm_provider', '')
        
        # ç¾¤èŠé»‘åå•é…ç½®
        group_blacklist_text = config.get('group_blacklist', '')
        self.group_blacklist = self._parse_group_list(group_blacklist_text)
        
        # åˆå¹¶è½¬å‘é…ç½®
        self.merge_forward_enabled = config.get('merge_forward_enabled', False)  # æ˜¯å¦å¯ç”¨åˆå¹¶è½¬å‘
        
        # è‡ªå®šä¹‰æç¤ºè¯é…ç½®
        self.custom_prompt = config.get('custom_prompt', '')  # è‡ªå®šä¹‰åˆ†ææç¤ºè¯
        
        self.analyzer = WebAnalyzer(self.max_content_length, self.timeout)
    
    def _parse_domain_list(self, domain_text: str) -> List[str]:
        """è§£æåŸŸååˆ—è¡¨æ–‡æœ¬ä¸ºåˆ—è¡¨"""
        if not domain_text:
            return []
        domains = [domain.strip() for domain in domain_text.split('\n') if domain.strip()]
        return domains
    
    def _parse_group_list(self, group_text: str) -> List[str]:
        """è§£æç¾¤èŠåˆ—è¡¨æ–‡æœ¬ä¸ºåˆ—è¡¨"""
        if not group_text:
            return []
        groups = [group.strip() for group in group_text.split('\n') if group.strip()]
        return groups
    
    def _is_group_blacklisted(self, group_id: str) -> bool:
        """æ£€æŸ¥ç¾¤èŠæ˜¯å¦åœ¨é»‘åå•ä¸­"""
        if not group_id or not self.group_blacklist:
            return False
        return group_id in self.group_blacklist
    
    def _is_domain_allowed(self, url: str) -> bool:
        """æ£€æŸ¥åŸŸåæ˜¯å¦å…è®¸è®¿é—®"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # æ£€æŸ¥æ˜¯å¦åœ¨ç¦æ­¢åˆ—è¡¨ä¸­
            if self.blocked_domains:
                for blocked_domain in self.blocked_domains:
                    if blocked_domain.lower() in domain:
                        return False
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼ˆå¦‚æœå…è®¸åˆ—è¡¨ä¸ä¸ºç©ºï¼‰
            if self.allowed_domains:
                for allowed_domain in self.allowed_domains:
                    if allowed_domain.lower() in domain:
                        return True
                return False  # å¦‚æœå…è®¸åˆ—è¡¨ä¸ä¸ºç©ºä½†åŸŸåä¸åœ¨å…¶ä¸­ï¼Œåˆ™ç¦æ­¢
            
            return True  # å¦‚æœå…è®¸åˆ—è¡¨ä¸ºç©ºï¼Œåˆ™å…è®¸æ‰€æœ‰åŸŸå
        except Exception:
            return False
    
    @filter.command("ç½‘é¡µåˆ†æ", alias={'åˆ†æ', 'æ€»ç»“'})
    async def analyze_webpage(self, event: AstrMessageEvent, url: str = None):
        """æ‰‹åŠ¨åˆ†ææŒ‡å®šç½‘é¡µé“¾æ¥"""
        if not url:
            yield event.plain_result("è¯·æä¾›è¦åˆ†æçš„ç½‘é¡µé“¾æ¥ï¼Œä¾‹å¦‚ï¼š/ç½‘é¡µåˆ†æ https://example.com")
            return
        
        if not self.analyzer.is_valid_url(url):
            yield event.plain_result("æ— æ•ˆçš„URLé“¾æ¥ï¼Œè¯·æ£€æŸ¥æ ¼å¼æ˜¯å¦æ­£ç¡®")
            return
        
        # æ£€æŸ¥åŸŸåæ˜¯å¦å…è®¸è®¿é—®
        if not self._is_domain_allowed(url):
            yield event.plain_result("è¯¥åŸŸåä¸åœ¨å…è®¸è®¿é—®çš„åˆ—è¡¨ä¸­ï¼Œæˆ–å·²è¢«ç¦æ­¢è®¿é—®")
            return
        
        yield event.plain_result(f"æ­£åœ¨åˆ†æç½‘é¡µ: {url}")
        
        async with WebAnalyzer(self.max_content_length, self.timeout, self.user_agent) as analyzer:
            # æŠ“å–ç½‘é¡µå†…å®¹
            html = await analyzer.fetch_webpage(url)
            if not html:
                yield event.plain_result("æ— æ³•æŠ“å–ç½‘é¡µå†…å®¹ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦å¯è®¿é—®")
                return
            
            # æå–å†…å®¹
            content_data = analyzer.extract_content(html, url)
            if not content_data:
                yield event.plain_result("æ— æ³•è§£æç½‘é¡µå†…å®¹")
                return
            
            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            analysis_result = await self.analyze_with_llm(event, content_data)
            
            # å‘é€åˆ†æç»“æœï¼Œä½¿ç”¨async forè¿­ä»£å¼‚æ­¥ç”Ÿæˆå™¨
            async for result in self._send_analysis_result(event, analysis_result, url):
                yield result
    
    @filter.event_message_type(filter.EventMessageType.ALL)
    async def auto_detect_urls(self, event: AstrMessageEvent):
        """è‡ªåŠ¨æ£€æµ‹æ¶ˆæ¯ä¸­çš„URLé“¾æ¥å¹¶è¿›è¡Œåˆ†æ"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨åˆ†æ
        if not self.auto_analyze:
            logger.info("è‡ªåŠ¨åˆ†æåŠŸèƒ½å·²ç¦ç”¨")
            return
        
        # æ£€æŸ¥ç¾¤èŠæ˜¯å¦åœ¨é»‘åå•ä¸­ï¼ˆä»…ç¾¤èŠæ¶ˆæ¯ï¼‰
        # å°è¯•ä»ä¸åŒä½ç½®è·å–ç¾¤èŠID
        group_id = None
        
        # æ–¹æ³•1ï¼šä»äº‹ä»¶å¯¹è±¡ç›´æ¥è·å–
        if hasattr(event, 'group_id') and event.group_id:
            group_id = event.group_id
        # æ–¹æ³•2ï¼šä»æ¶ˆæ¯å¯¹è±¡è·å–
        elif hasattr(event, 'message_obj') and hasattr(event.message_obj, 'group_id') and event.message_obj.group_id:
            group_id = event.message_obj.group_id
        # æ–¹æ³•3ï¼šä»åŸå§‹æ¶ˆæ¯è·å–
        elif hasattr(event, 'raw_message') and hasattr(event.raw_message, 'group_id') and event.raw_message.group_id:
            group_id = event.raw_message.group_id
        
        # ç¾¤èŠåœ¨é»‘åå•ä¸­æ—¶é™é»˜å¿½ç•¥
        if group_id and self._is_group_blacklisted(group_id):
            return  # ç¾¤èŠåœ¨é»‘åå•ä¸­ï¼Œé™é»˜å¿½ç•¥
            
        message_text = event.message_str
        
        # æå–URL
        urls = self.analyzer.extract_urls(message_text)
        if not urls:
            return  # æ²¡æœ‰URLï¼Œä¸å¤„ç†
        
        valid_urls = [url for url in urls if self.analyzer.is_valid_url(url)]
        if not valid_urls:
            return
        
        # åªå¤„ç†ç¬¬ä¸€ä¸ªURLï¼Œé¿å…è¿‡å¤šè¯·æ±‚
        url = valid_urls[0]
        
        # æ£€æŸ¥åŸŸåæ˜¯å¦å…è®¸è®¿é—®
        if not self._is_domain_allowed(url):
            return  # åŸŸåä¸å…è®¸è®¿é—®ï¼Œé™é»˜å¿½ç•¥
        
        # å‘é€å¤„ç†æç¤º
        yield event.plain_result(f"æ£€æµ‹åˆ°ç½‘é¡µé“¾æ¥ï¼Œæ­£åœ¨åˆ†æ: {url}")
        
        async with WebAnalyzer(self.max_content_length, self.timeout, self.user_agent) as analyzer:
            # æŠ“å–ç½‘é¡µå†…å®¹
            html = await analyzer.fetch_webpage(url)
            if not html:
                yield event.plain_result("æ— æ³•æŠ“å–ç½‘é¡µå†…å®¹")
                return
            
            # æå–å†…å®¹
            content_data = analyzer.extract_content(html, url)
            if not content_data:
                yield event.plain_result("æ— æ³•è§£æç½‘é¡µå†…å®¹")
                return
            
            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            analysis_result = await self.analyze_with_llm(event, content_data)
            
            # å‘é€åˆ†æç»“æœï¼Œæ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨åˆå¹¶è½¬å‘
            async for result in self._send_analysis_result(event, analysis_result, url):
                yield result
    
    async def analyze_with_llm(self, event: AstrMessageEvent, content_data: dict) -> str:
        """è°ƒç”¨LLMè¿›è¡Œå†…å®¹åˆ†æå’Œæ€»ç»“"""
        try:
            title = content_data['title']
            content = content_data['content']
            url = content_data['url']
            
            # æ£€æŸ¥LLMæ˜¯å¦å¯ç”¨å’Œå¯ç”¨
            if not hasattr(self.context, 'llm_generate') or not self.llm_enabled:
                return self.get_enhanced_analysis(content_data)
            
            # ä¼˜å…ˆä½¿ç”¨é…ç½®çš„LLMæä¾›å•†ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨å½“å‰ä¼šè¯çš„æ¨¡å‹
            provider_id = self.llm_provider
            if not provider_id:
                umo = event.unified_msg_origin
                provider_id = await self.context.get_current_chat_provider_id(umo=umo)
            
            if not provider_id:
                return self.get_enhanced_analysis(content_data)
            
            # æ„å»ºä¼˜åŒ–çš„LLMæç¤ºè¯
            emoji_prefix = "æ¯ä¸ªè¦ç‚¹ç”¨emojiå›¾æ ‡æ ‡è®°" if self.enable_emoji else ""
            
            # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯æˆ–é»˜è®¤æç¤ºè¯
            if self.custom_prompt:
                # æ›¿æ¢è‡ªå®šä¹‰æç¤ºè¯ä¸­çš„å˜é‡
                prompt = self.custom_prompt.format(
                    title=title,
                    url=url,
                    content=content,
                    max_length=self.max_summary_length
                )
            else:
                # é»˜è®¤æç¤ºè¯
                prompt = f"""è¯·å¯¹ä»¥ä¸‹ç½‘é¡µå†…å®¹è¿›è¡Œä¸“ä¸šåˆ†æå’Œæ™ºèƒ½æ€»ç»“ï¼š

**ç½‘é¡µä¿¡æ¯**
- æ ‡é¢˜ï¼š{title}
- é“¾æ¥ï¼š{url}

**ç½‘é¡µå†…å®¹**ï¼š
{content}

**åˆ†æè¦æ±‚**ï¼š
1. **æ ¸å¿ƒæ‘˜è¦**ï¼šç”¨50-100å­—æ¦‚æ‹¬ç½‘é¡µçš„æ ¸å¿ƒå†…å®¹å’Œä¸»æ—¨
2. **å…³é”®è¦ç‚¹**ï¼šæå–2-3ä¸ªæœ€é‡è¦çš„ä¿¡æ¯ç‚¹æˆ–è§‚ç‚¹
3. **å†…å®¹ç±»å‹**ï¼šåˆ¤æ–­ç½‘é¡µå±äºä»€ä¹ˆç±»å‹ï¼ˆæ–°é—»ã€æ•™ç¨‹ã€åšå®¢ã€äº§å“ä»‹ç»ç­‰ï¼‰
4. **ä»·å€¼è¯„ä¼°**ï¼šç®€è¦è¯„ä»·å†…å®¹çš„ä»·å€¼å’Œå®ç”¨æ€§
5. **é€‚ç”¨äººç¾¤**ï¼šè¯´æ˜é€‚åˆå“ªäº›äººç¾¤é˜…è¯»

**è¾“å‡ºæ ¼å¼è¦æ±‚**ï¼š
- ä½¿ç”¨æ¸…æ™°çš„åˆ†æ®µç»“æ„
- {emoji_prefix}
- è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œé¿å…å†—ä½™
- ä¿æŒå®¢è§‚ä¸­ç«‹çš„æ€åº¦
- æ€»å­—æ•°ä¸è¶…è¿‡{self.max_summary_length}å­—

è¯·ç¡®ä¿åˆ†æå‡†ç¡®ã€å…¨é¢ä¸”æ˜“äºç†è§£ã€‚"""
            
            # ä½¿ç”¨å½“å‰ä¼šè¯çš„èŠå¤©æ¨¡å‹IDè°ƒç”¨å¤§æ¨¡å‹
            llm_resp = await self.context.llm_generate(
                chat_provider_id=provider_id,  # ä½¿ç”¨å½“å‰ä¼šè¯çš„èŠå¤©æ¨¡å‹
                prompt=prompt
            )
            
            if llm_resp and llm_resp.completion_text:
                # ç¾åŒ–LLMè¿”å›çš„ç»“æœ
                analysis_text = llm_resp.completion_text.strip()
                
                # é™åˆ¶æ‘˜è¦é•¿åº¦
                if len(analysis_text) > self.max_summary_length:
                    analysis_text = analysis_text[:self.max_summary_length] + "..."
                
                # æ·»åŠ æ ‡é¢˜å’Œæ ¼å¼ç¾åŒ–
                link_emoji = "ğŸ”—" if self.enable_emoji else ""
                title_emoji = "ğŸ“" if self.enable_emoji else ""
                
                formatted_result = f"**AIæ™ºèƒ½ç½‘é¡µåˆ†ææŠ¥å‘Š**\n\n"
                formatted_result += f"{link_emoji} **åˆ†æé“¾æ¥**: {url}\n"
                formatted_result += f"{title_emoji} **ç½‘é¡µæ ‡é¢˜**: {title}\n\n"
                formatted_result += "---\n\n"
                formatted_result += analysis_text
                formatted_result += "\n\n---\n"
                formatted_result += "*åˆ†æå®Œæˆï¼Œå¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©ï¼*"
                
                return formatted_result
            else:
                return self.get_enhanced_analysis(content_data)
                
        except Exception as e:
            logger.error(f"LLMåˆ†æå¤±è´¥: {e}")
            # å¦‚æœLLMåˆ†æå¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯
            return f"âŒ LLMåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    def get_enhanced_analysis(self, content_data: dict) -> str:
        """å¢å¼ºç‰ˆåŸºç¡€åˆ†æï¼ˆLLMä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        title = content_data['title']
        content = content_data['content']
        url = content_data['url']
        
        # è¯¦ç»†çš„å†…å®¹ç»Ÿè®¡
        char_count = len(content)
        line_count = len(content.split('\n'))
        word_count = len(content.split())
        
        # æ™ºèƒ½å†…å®¹ç±»å‹æ£€æµ‹
        content_lower = content.lower()
        content_type = "æ–‡ç« "
        if any(keyword in content_lower for keyword in ['æ–°é—»', 'æŠ¥é“', 'æ¶ˆæ¯', 'æ—¶äº‹']):
            content_type = "æ–°é—»èµ„è®¯"
        elif any(keyword in content_lower for keyword in ['æ•™ç¨‹', 'æŒ‡å—', 'æ•™å­¦', 'æ­¥éª¤', 'æ–¹æ³•']):
            content_type = "æ•™ç¨‹æŒ‡å—"
        elif any(keyword in content_lower for keyword in ['åšå®¢', 'éšç¬”', 'æ—¥è®°', 'ä¸ªäºº', 'è§‚ç‚¹']):
            content_type = "ä¸ªäººåšå®¢"
        elif any(keyword in content_lower for keyword in ['äº§å“', 'æœåŠ¡', 'è´­ä¹°', 'ä»·æ ¼', 'ä¼˜æƒ ']):
            content_type = "äº§å“ä»‹ç»"
        elif any(keyword in content_lower for keyword in ['æŠ€æœ¯', 'å¼€å‘', 'ç¼–ç¨‹', 'ä»£ç ', 'API']):
            content_type = "æŠ€æœ¯æ–‡æ¡£"
        
        # æå–å…³é”®å¥å­ï¼ˆå‰3ä¸ªéç©ºæ®µè½ï¼‰
        paragraphs = [p.strip() for p in content.split('\n') if p.strip()]
        key_sentences = paragraphs[:3]
        
        # æ£€æµ‹å†…å®¹è´¨é‡
        quality_indicator = "å†…å®¹ä¸°å¯Œ" if char_count > 1000 else "å†…å®¹ç®€æ´"
        if char_count > 5000:
            quality_indicator = "å†…å®¹è¯¦å®"
        
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨emoji
        robot_emoji = "ğŸ¤–" if self.enable_emoji else ""
        page_emoji = "ğŸ“„" if self.enable_emoji else ""
        info_emoji = "ğŸ“" if self.enable_emoji else ""
        stats_emoji = "ğŸ“Š" if self.enable_emoji else ""
        search_emoji = "ğŸ”" if self.enable_emoji else ""
        light_emoji = "ğŸ’¡" if self.enable_emoji else ""
        
        result = f"{robot_emoji} **æ™ºèƒ½ç½‘é¡µåˆ†æ** {page_emoji}\n\n"
        
        if self.enable_emoji:
            result += f"**{info_emoji} åŸºæœ¬ä¿¡æ¯**\n"
        else:
            result += f"**åŸºæœ¬ä¿¡æ¯**\n"
        result += f"- **æ ‡é¢˜**: {title}\n"
        result += f"- **é“¾æ¥**: {url}\n"
        result += f"- **å†…å®¹ç±»å‹**: {content_type}\n"
        result += f"- **è´¨é‡è¯„ä¼°**: {quality_indicator}\n\n"
        
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if self.enable_statistics:
            if self.enable_emoji:
                result += f"**{stats_emoji} å†…å®¹ç»Ÿè®¡**\n"
            else:
                result += f"**å†…å®¹ç»Ÿè®¡**\n"
            result += f"- å­—ç¬¦æ•°: {char_count:,}\n"
            result += f"- æ®µè½æ•°: {len(paragraphs)}\n"
            result += f"- è¯æ•°: {word_count:,}\n\n"
        
        if self.enable_emoji:
            result += f"**{search_emoji} å†…å®¹æ‘˜è¦**\n"
        else:
            result += f"**å†…å®¹æ‘˜è¦**\n"
        result += f"{chr(10).join(['â€¢ ' + sentence[:100] + ('...' if len(sentence) > 100 else '') for sentence in key_sentences])}\n\n"
        
        if self.enable_emoji:
            result += f"**{light_emoji} åˆ†æè¯´æ˜**\n"
        else:
            result += f"**åˆ†æè¯´æ˜**\n"
        result += "æ­¤åˆ†æåŸºäºç½‘é¡µå†…å®¹æå–ï¼Œå¦‚éœ€æ›´æ·±å…¥çš„AIæ™ºèƒ½åˆ†æï¼Œè¯·ç¡®ä¿AstrBotå·²æ­£ç¡®é…ç½®LLMåŠŸèƒ½ã€‚\n\n"
        result += "*æç¤ºï¼šå®Œæ•´å†…å®¹é¢„è§ˆè¯·æŸ¥çœ‹åŸå§‹ç½‘é¡µ*"
        
        return result
    
    @filter.command("web_config", alias={'ç½‘é¡µåˆ†æé…ç½®', 'ç½‘é¡µåˆ†æè®¾ç½®'})
    async def show_config(self, event: AstrMessageEvent):
        """æ˜¾ç¤ºå½“å‰æ’ä»¶é…ç½®"""
        config_info = f"""**ç½‘é¡µåˆ†ææ’ä»¶é…ç½®ä¿¡æ¯**

**åŸºæœ¬è®¾ç½®**
- æœ€å¤§å†…å®¹é•¿åº¦: {self.max_content_length} å­—ç¬¦
- è¯·æ±‚è¶…æ—¶æ—¶é—´: {self.timeout} ç§’
- LLMæ™ºèƒ½åˆ†æ: {'âœ… å·²å¯ç”¨' if self.llm_enabled else 'âŒ å·²ç¦ç”¨'}
- è‡ªåŠ¨åˆ†æé“¾æ¥: {'âœ… å·²å¯ç”¨' if self.auto_analyze else 'âŒ å·²ç¦ç”¨'}
- åˆå¹¶è½¬å‘åŠŸèƒ½: {'âœ… å·²å¯ç”¨' if self.merge_forward_enabled else 'âŒ å·²ç¦ç”¨'}

**åŸŸåæ§åˆ¶**
- å…è®¸åŸŸå: {len(self.allowed_domains)} ä¸ª
- ç¦æ­¢åŸŸå: {len(self.blocked_domains)} ä¸ª

**ç¾¤èŠæ§åˆ¶**
- ç¾¤èŠé»‘åå•: {len(self.group_blacklist)} ä¸ªç¾¤èŠ

**åˆ†æè®¾ç½®**
- å¯ç”¨emoji: {'âœ… å·²å¯ç”¨' if self.enable_emoji else 'âŒ å·²ç¦ç”¨'}
- æ˜¾ç¤ºç»Ÿè®¡: {'âœ… å·²å¯ç”¨' if self.enable_statistics else 'âŒ å·²ç¦ç”¨'}
- æœ€å¤§æ‘˜è¦é•¿åº¦: {self.max_summary_length} å­—ç¬¦

**LLMé…ç½®**
- æŒ‡å®šæä¾›å•†: {self.llm_provider if self.llm_provider else 'ä½¿ç”¨ä¼šè¯é»˜è®¤'}
- è‡ªå®šä¹‰æç¤ºè¯: {'âœ… å·²å¯ç”¨' if self.custom_prompt else 'âŒ æœªè®¾ç½®'}

*æç¤º: å¦‚éœ€ä¿®æ”¹é…ç½®ï¼Œè¯·åœ¨AstrBotç®¡ç†é¢æ¿ä¸­ç¼–è¾‘æ’ä»¶é…ç½®*"""
        
        yield event.plain_result(config_info)
    
    @filter.command("test_merge", alias={'æµ‹è¯•åˆå¹¶è½¬å‘', 'æµ‹è¯•è½¬å‘'})
    async def test_merge_forward(self, event: AstrMessageEvent):
        '''æµ‹è¯•åˆå¹¶è½¬å‘åŠŸèƒ½'''
        from astrbot.api.message_components import Node, Plain, Nodes
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¾¤èŠæ¶ˆæ¯
        group_id = None
        if hasattr(event, 'group_id') and event.group_id:
            group_id = event.group_id
        elif hasattr(event, 'message_obj') and hasattr(event.message_obj, 'group_id') and event.message_obj.group_id:
            group_id = event.message_obj.group_id
        
        if group_id:
            # åˆ›å»ºæµ‹è¯•ç”¨çš„åˆå¹¶è½¬å‘èŠ‚ç‚¹
            nodes = []
            
            # æ ‡é¢˜èŠ‚ç‚¹
            title_node = Node(
                uin=event.get_sender_id(),
                name="æµ‹è¯•åˆå¹¶è½¬å‘",
                content=[
                    Plain("è¿™æ˜¯åˆå¹¶è½¬å‘æµ‹è¯•æ¶ˆæ¯")
                ]
            )
            nodes.append(title_node)
            
            # å†…å®¹èŠ‚ç‚¹1
            content_node1 = Node(
                uin=event.get_sender_id(),
                name="æµ‹è¯•èŠ‚ç‚¹1",
                content=[
                    Plain("è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•èŠ‚ç‚¹å†…å®¹")
                ]
            )
            nodes.append(content_node1)
            
            # å†…å®¹èŠ‚ç‚¹2
            content_node2 = Node(
                uin=event.get_sender_id(),
                name="æµ‹è¯•èŠ‚ç‚¹2",
                content=[
                    Plain("è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•èŠ‚ç‚¹å†…å®¹")
                ]
            )
            nodes.append(content_node2)
            
            # ä½¿ç”¨NodesåŒ…è£…æ‰€æœ‰èŠ‚ç‚¹ï¼Œåˆå¹¶æˆä¸€ä¸ªåˆå¹¶è½¬å‘æ¶ˆæ¯
            merge_forward_message = Nodes(nodes)
            yield event.chain_result([merge_forward_message])
            logger.info(f"æµ‹è¯•åˆå¹¶è½¬å‘åŠŸèƒ½ï¼Œç¾¤èŠ {group_id}")
        else:
            yield event.plain_result("åˆå¹¶è½¬å‘åŠŸèƒ½ä»…æ”¯æŒç¾¤èŠæ¶ˆæ¯æµ‹è¯•")
            logger.info("ç§èŠæ¶ˆæ¯æ— æ³•æµ‹è¯•åˆå¹¶è½¬å‘åŠŸèƒ½")
    
    @filter.command("group_blacklist", alias={'ç¾¤é»‘åå•', 'é»‘åå•'})
    async def manage_group_blacklist(self, event: AstrMessageEvent):
        """ç®¡ç†ç¾¤èŠé»‘åå•"""
        # è§£æå‘½ä»¤å‚æ•°
        message_parts = event.message_str.strip().split()
        
        # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œæ˜¾ç¤ºå½“å‰é»‘åå•
        if len(message_parts) <= 1:
            if not self.group_blacklist:
                yield event.plain_result("å½“å‰ç¾¤èŠé»‘åå•ä¸ºç©º")
                return
            
            blacklist_info = "**å½“å‰ç¾¤èŠé»‘åå•**\n\n"
            for i, group_id in enumerate(self.group_blacklist, 1):
                blacklist_info += f"{i}. {group_id}\n"
            
            blacklist_info += "\nä½¿ç”¨ `/group_blacklist add <ç¾¤å·>` æ·»åŠ ç¾¤èŠåˆ°é»‘åå•"
            blacklist_info += "\nä½¿ç”¨ `/group_blacklist remove <ç¾¤å·>` ä»é»‘åå•ç§»é™¤ç¾¤èŠ"
            blacklist_info += "\nä½¿ç”¨ `/group_blacklist clear` æ¸…ç©ºé»‘åå•"
            
            yield event.plain_result(blacklist_info)
            return
        
        action = message_parts[1].lower() if len(message_parts) > 1 else ""
        group_id = message_parts[2] if len(message_parts) > 2 else ""
        
        if action == "add" and group_id:
            # æ·»åŠ ç¾¤èŠåˆ°é»‘åå•
            if group_id in self.group_blacklist:
                yield event.plain_result(f"ç¾¤èŠ {group_id} å·²åœ¨é»‘åå•ä¸­")
                return
            
            self.group_blacklist.append(group_id)
            self._save_group_blacklist()
            yield event.plain_result(f"âœ… å·²æ·»åŠ ç¾¤èŠ {group_id} åˆ°é»‘åå•")
            
        elif action == "remove" and group_id:
            # ä»é»‘åå•ç§»é™¤ç¾¤èŠ
            if group_id not in self.group_blacklist:
                yield event.plain_result(f"ç¾¤èŠ {group_id} ä¸åœ¨é»‘åå•ä¸­")
                return
            
            self.group_blacklist.remove(group_id)
            self._save_group_blacklist()
            yield event.plain_result(f"âœ… å·²ä»é»‘åå•ç§»é™¤ç¾¤èŠ {group_id}")
            
        elif action == "clear":
            # æ¸…ç©ºé»‘åå•
            if not self.group_blacklist:
                yield event.plain_result("é»‘åå•å·²ä¸ºç©º")
                return
            
            self.group_blacklist.clear()
            self._save_group_blacklist()
            yield event.plain_result("âœ… å·²æ¸…ç©ºç¾¤èŠé»‘åå•")
            
        else:
            yield event.plain_result("æ— æ•ˆçš„æ“ä½œï¼Œè¯·ä½¿ç”¨: add <ç¾¤å·>, remove <ç¾¤å·>, clear")
    
    def _save_group_blacklist(self):
        """ä¿å­˜ç¾¤èŠé»‘åå•åˆ°é…ç½®"""
        try:
            # å°†ç¾¤èŠåˆ—è¡¨è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
            group_text = '\n'.join(self.group_blacklist)
            # æ›´æ–°é…ç½®å¹¶ä¿å­˜
            self.config['group_blacklist'] = group_text
            self.config.save_config()
        except Exception as e:
            logger.error(f"ä¿å­˜ç¾¤èŠé»‘åå•å¤±è´¥: {e}")
    
    async def _send_analysis_result(self, event, analysis_result, url):
        '''å‘é€åˆ†æç»“æœï¼Œæ ¹æ®å¼€å…³å†³å®šæ˜¯å¦ä½¿ç”¨åˆå¹¶è½¬å‘'''
        from astrbot.api.message_components import Node, Plain, Nodes
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¾¤èŠæ¶ˆæ¯ä¸”åˆå¹¶è½¬å‘åŠŸèƒ½å·²å¯ç”¨
        group_id = None
        if hasattr(event, 'group_id') and event.group_id:
            group_id = event.group_id
        elif hasattr(event, 'message_obj') and hasattr(event.message_obj, 'group_id') and event.message_obj.group_id:
            group_id = event.message_obj.group_id
        
        # å¦‚æœæ˜¯ç¾¤èŠæ¶ˆæ¯ä¸”åˆå¹¶è½¬å‘åŠŸèƒ½å·²å¯ç”¨ï¼Œä½¿ç”¨åˆå¹¶è½¬å‘
        if group_id and self.merge_forward_enabled:
            # ä½¿ç”¨åˆå¹¶è½¬å‘ - å°†æ•´ä¸ªåˆ†æç»“æœä½œä¸ºä¸€ä¸ªå®Œæ•´çš„èŠ‚ç‚¹å‘é€
            nodes = []
            
            # æ·»åŠ æ ‡é¢˜èŠ‚ç‚¹
            title_node = Node(
                uin=event.get_sender_id(),
                name="ç½‘é¡µåˆ†æç»“æœ",
                content=[
                    Plain(f"ç½‘é¡µåˆ†æç»“æœ - {url}")
                ]
            )
            nodes.append(title_node)
            
            # æ·»åŠ å†…å®¹èŠ‚ç‚¹ - æ•´ä¸ªåˆ†æç»“æœä½œä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œä¸åˆ†æ®µ
            content_node = Node(
                uin=event.get_sender_id(),
                name="è¯¦ç»†åˆ†æ",
                content=[
                    Plain(analysis_result)
                ]
            )
            nodes.append(content_node)
            
            # ä½¿ç”¨NodesåŒ…è£…æ‰€æœ‰èŠ‚ç‚¹ï¼Œåˆå¹¶æˆä¸€ä¸ªåˆå¹¶è½¬å‘æ¶ˆæ¯
            merge_forward_message = Nodes(nodes)
            
            # å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯
            yield event.chain_result([merge_forward_message])
            logger.info(f"ç¾¤èŠ {group_id} ä½¿ç”¨åˆå¹¶è½¬å‘å‘é€åˆ†æç»“æœï¼Œä¸åˆ†æ®µ")
        else:
            # æ™®é€šå‘é€
            result_text = f"ç½‘é¡µåˆ†æç»“æœï¼š\n{analysis_result}"
            yield event.plain_result(result_text)
            message_type = "ç¾¤èŠ" if group_id else "ç§èŠ"
            logger.info(f"{message_type}æ¶ˆæ¯æ™®é€šå‘é€åˆ†æç»“æœ")
    
    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        logger.info("ç½‘é¡µåˆ†ææ’ä»¶å·²å¸è½½")